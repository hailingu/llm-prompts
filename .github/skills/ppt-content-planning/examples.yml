# Structured examples for automated tests and documentation

examples:
  - name: technical_review_planning
    description: "Content planning for technical review presentation (expert audience, high technical depth)"
    input:
      source_doc: "docs/specs/online-ps-algorithm-v1.md"
      audience_type: "technical_reviewers"
      knowledge_level: "expert"
      time_constraint: "30min"
      philosophy: "McKinsey Pyramid"
    expected_output:
      status: success
      slides_count: 16
      philosophy: "McKinsey Pyramid"
      visual_types_used: 
        - "architecture_diagram"
        - "flow_diagram"
        - "comparison_table"
        - "kpi_dashboard"
      qa_checks_passed: 10
      front_matter_valid: true
      speaker_notes_complete: true

  - name: executive_summary_planning
    description: "Content planning for executive summary (decision-makers, low technical depth)"
    input:
      source_doc: "docs/proposals/project-alpha.md"
      audience_type: "executive"
      knowledge_level: "intermediate"
      time_constraint: "15min"
      philosophy: "Presentation Zen"
    expected_output:
      status: success
      slides_count: 8
      philosophy: "Presentation Zen"
      visual_types_used:
        - "bar_chart"
        - "timeline"
        - "kpi_dashboard"
      qa_checks_passed: 10
      bullet_limit_respected: true

  - name: missing_context_warning
    description: "Partial success when source document lacks key decisions"
    input:
      source_doc: "docs/drafts/incomplete-spec.md"
      audience_type: "technical_reviewers"
    expected_output:
      status: partial
      slides_count: 6
      qa_checks_passed: 7
      qa_checks_failed: 3
      warnings:
        - "Key decisions extraction yielded only 2 items (expected â‰¥3)"
        - "Speaker notes missing evidence traceability for slide 4"
        - "Visual type 'comparison_table' has insufficient data rows"
